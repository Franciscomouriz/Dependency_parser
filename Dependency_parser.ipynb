{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 10:16:36.671847: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-20 10:16:37.199571: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-20 10:16:37.202957: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-20 10:16:39.373835: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from process_data import ProcessData\n",
    "from dependency_parser import DependencyParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow and Keras versions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow  2.12.0\n",
      "Keras  2.12.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow \", tf.__version__)\n",
    "print(\"Keras \", keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_data_url():\n",
    "    train_file_url = \"https://raw.githubusercontent.com/UniversalDependencies/UD_English-ParTUT/master/en_partut-ud-train.conllu\"\n",
    "    test_file_url = \"https://raw.githubusercontent.com/UniversalDependencies/UD_English-ParTUT/master/en_partut-ud-test.conllu\"\n",
    "    dev_file_url = \"https://raw.githubusercontent.com/UniversalDependencies/UD_English-ParTUT/master/en_partut-ud-dev.conllu\"\n",
    "    \n",
    "    return train_file_url, test_file_url, dev_file_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_model(n_features=2, new_model=False, new_samples=False):\n",
    "    train = False\n",
    "\n",
    "    if n_features <= 0:\n",
    "        raise ValueError(\"Number of features must be over 0\")\n",
    "    \n",
    "    try:\n",
    "        train_file_url, test_file_url, dev_file_url = obtain_data_url()\n",
    "    except:\n",
    "        print(\"Data not found, please check the url\")\n",
    "        return None\n",
    "    \n",
    "    # If a model already exists, load it and put train to False\n",
    "    try:\n",
    "        if new_model == True:\n",
    "            print(\"Creating a new model, the old one will be deleted\")\n",
    "            raise Exception(\"Creating a new model, the old one will be deleted\")\n",
    "\n",
    "        # Create the object to process the data\n",
    "        processData = ProcessData(train_file_url, test_file_url, dev_file_url)\n",
    "        processData.read_conllu_file(type_file=\"test\")\n",
    "        processData.create_samples(\"test\", new_samples = new_samples)\n",
    "        # Load model and tokenizer\n",
    "        dependencyParser = DependencyParser(processData)\n",
    "        dependencyParser.load_model(\"models/\" + str(n_features) + \"_features_parser.h5\")\n",
    "        dependencyParser.load_tokenizer(\"models/tokenizer.pickle\")\n",
    "        print(\"Model found, loading it\")\n",
    "        dependencyParser.prepare_test_data(n_features=n_features)\n",
    "        dependencyParser.evaluate_model()\n",
    "        # Evaluate the model with the dev data\n",
    "        predictions = dependencyParser.predict(processData.test_data[\"dataframes\"], n_features=n_features)\n",
    "        dependencyParser.conllu_evaluation(predictions, n_features=n_features)\n",
    "\n",
    "        train = False\n",
    "    except:\n",
    "        train = True\n",
    "        if new_model != True:\n",
    "            print(\"No model found, creating a new one\")\n",
    "\n",
    "    if train == True:\n",
    "        # Create the object to process the data\n",
    "        processData = ProcessData(train_file_url, test_file_url, dev_file_url)\n",
    "\n",
    "        # Read the files\n",
    "        processData.read_conllu_file(type_file=\"train\")\n",
    "        processData.read_conllu_file(type_file=\"test\")\n",
    "        processData.read_conllu_file(type_file=\"dev\")\n",
    "\n",
    "        # Create the samples\n",
    "        processData.create_samples(\"train\", new_samples = new_samples)\n",
    "        processData.create_samples(\"test\", new_samples = new_samples)\n",
    "        processData.create_samples(\"dev\", new_samples = new_samples)\n",
    "\n",
    "        # Create the object to use the model\n",
    "        dependencyParser = DependencyParser(processData)\n",
    "\n",
    "        # Create the tokenizer\n",
    "        dependencyParser.create_tokenizer(processData.train_data[\"words\"])\n",
    "\n",
    "        # Prepare the data\n",
    "        dependencyParser.prepare_data(n_features=n_features)\n",
    "        \n",
    "\n",
    "        # Create and train the model\n",
    "        dependencyParser.create_and_fit_model(n_features = n_features)\n",
    "\n",
    "        # Evaluate the model with the dev data\n",
    "        predictions = dependencyParser.predict(processData.test_data[\"dataframes\"], n_features=n_features)\n",
    "        dependencyParser.conllu_evaluation(predictions, n_features=n_features)\n",
    "\n",
    "        # Save the model and the tokenizer\n",
    "        dependencyParser.save_model(\"models/\" + str(n_features) + \"_features_parser.h5\")\n",
    "        dependencyParser.save_tokenizer(\"models/tokenizer.pickle\")\n",
    "        \n",
    "    return dependencyParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model found, loading it\n",
      "205/205 [==============================] - 2s 5ms/step - loss: 1.8781 - output1_loss: 0.7728 - output2_loss: 1.1053 - output1_accuracy: 0.8154 - output2_accuracy: 0.7991\n",
      "test loss, test acc: [1.8780925273895264, 0.7728299498558044, 1.1052625179290771, 0.8154198527336121, 0.799083948135376]\n",
      "\n",
      "\n",
      "Evaluate on dev data\n",
      "Predicting...\n",
      "5/5 [==============================] - 1s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "LAS F1 Score: 53.51\n",
      "MLAS Score: 43.27\n",
      "BLEX Score: 45.12\n",
      "Metric     | Precision |    Recall |  F1 Score | AligndAcc\n",
      "-----------+-----------+-----------+-----------+-----------\n",
      "Tokens     |    100.00 |    100.00 |    100.00 |\n",
      "Sentences  |    100.00 |    100.00 |    100.00 |\n",
      "Words      |    100.00 |    100.00 |    100.00 |\n",
      "UPOS       |    100.00 |    100.00 |    100.00 |    100.00\n",
      "XPOS       |    100.00 |    100.00 |    100.00 |    100.00\n",
      "UFeats     |    100.00 |    100.00 |    100.00 |    100.00\n",
      "AllTags    |    100.00 |    100.00 |    100.00 |    100.00\n",
      "Lemmas     |    100.00 |    100.00 |    100.00 |    100.00\n",
      "UAS        |     65.09 |     65.09 |     65.09 |     65.09\n",
      "LAS        |     53.51 |     53.51 |     53.51 |     53.51\n",
      "CLAS       |     51.19 |     40.33 |     45.12 |     40.33\n",
      "MLAS       |     49.09 |     38.68 |     43.27 |     38.68\n",
      "BLEX       |     51.19 |     40.33 |     45.12 |     40.33\n"
     ]
    }
   ],
   "source": [
    "dependencyParser = select_model(n_features=2, new_model=False, new_samples=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
